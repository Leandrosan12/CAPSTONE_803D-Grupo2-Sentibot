# -*- coding: utf-8 -*-
"""SentibotCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v4B7zQu_XOtiPa2wqT-yeWm6R7F_kTya
"""

!pip uninstall -y deeplake
!pip install "deeplake<4"


import deeplake

# Ahora s√≠ funciona con .load()
train_ds = deeplake.load('hub://activeloop/fer2013-train')
test_ds  = deeplake.load('hub://activeloop/fer2013-public-test')

print(train_ds.summary())

from collections import Counter

# Extraer todas las etiquetas del dataset
labels = [int(sample.labels.numpy()) for sample in train_ds]

# Contar todas las clases
counts_all = Counter(labels)

# Mostrar todas las emociones
emotions_all_map = {
    0:"Enojo", 1:"Asco", 2:"Miedo", 3:"Alegr√≠a",
    4:"Tristeza", 5:"Sorpresa", 6:"Neutral"
}

print("Conteo de todas las emociones:")
for k, name in emotions_all_map.items():
    print(f"{name}: {counts_all[k]} im√°genes")

from collections import Counter

# Extraer todas las etiquetas del dataset
labels = [int(sample.labels.numpy()) for sample in train_ds]

# Contar cantidad por clase
counts = Counter(labels)

# Mostrar solo las 5 emociones que quieres
emotions_map = {0:"Enojo", 1:"Asco", 2:"Miedo", 3:"Alegr√≠a", 4:"Tristeza"}

for k, name in emotions_map.items():
    print(f"{name}: {counts[k]} im√°genes")

import matplotlib.pyplot as plt

# Par√°metros
num_images_per_emotion = 5
num_emotions = len(emotions_map)

# Crear grid: filas = emociones, columnas = im√°genes por emoci√≥n
fig, axes = plt.subplots(num_emotions, num_images_per_emotion, figsize=(15, 12))

# Aplanar axes si solo hay una fila/columna
if num_emotions == 1:
    axes = [axes]
if num_images_per_emotion == 1:
    axes = [[ax] for ax in axes]

# Mostrar im√°genes
for row_idx, (label, name) in enumerate(emotions_map.items()):
    count = 0
    for sample in train_ds:
        if int(sample.labels.numpy()) == label:
            axes[row_idx, count].imshow(sample.images.numpy(), cmap='gray')
            axes[row_idx, count].set_title(name, fontsize=10)
            axes[row_idx, count].axis('off')
            count += 1
        if count >= num_images_per_emotion:
            break

plt.tight_layout()
plt.show()

from collections import Counter

# Definir las 5 emociones que quieres
emotions_map = {0:"Enojo", 1:"Asco", 2:"Miedo", 3:"Alegr√≠a", 4:"Tristeza"}

# Extraer etiquetas del test set y convertir de Tensor a int
test_labels = [int(sample.labels.numpy()) for sample in test_ds]

# Contar cu√°ntas hay de cada clase
counts_test = Counter(test_labels)

# Mostrar solo las 5 emociones seleccionadas
print("Conteo de im√°genes por emoci√≥n en el test set:")
for label, name in emotions_map.items():
    print(f"{name}: {counts_test[label]} im√°genes")

import os
from pathlib import Path
from PIL import Image
import numpy as np
from collections import Counter

# Emociones que queremos
emotions_map = {0:"Enojo", 1:"Asco", 2:"Miedo", 3:"Alegr√≠a", 4:"Tristeza"}

# Carpeta base donde guardar las im√°genes
base_dir = "/content/emociones_dataset/train"
os.makedirs(base_dir, exist_ok=True)

# Crear subcarpetas por emoci√≥n
for name in emotions_map.values():
    Path(os.path.join(base_dir, name)).mkdir(parents=True, exist_ok=True)

# Funci√≥n para guardar imagen
def save_image(img_array, path, filename):
    if img_array.max() <= 1:
        img_array = (img_array * 255).astype(np.uint8)
    else:
        img_array = img_array.astype(np.uint8)
    # Escala de grises (48,48,1) ‚Üí (48,48)
    if len(img_array.shape) == 3 and img_array.shape[-1] == 1:
        img_array = img_array.squeeze(-1)
    img = Image.fromarray(img_array)
    img.save(os.path.join(path, filename))

# Contadores para nombrar archivos por clase
counters = {label:0 for label in emotions_map.keys()}

# Recorrer todo el dataset DeepLake
for i in range(len(train_ds)):
    img_tensor = train_ds[i]["images"]   # o "image" seg√∫n tu dataset
    label_tensor = train_ds[i]["labels"] # o "label"

    # Convertir tensor a entero
    try:
        label = int(label_tensor.numpy())  # TensorFlow
    except:
        label = int(label_tensor.detach().cpu().numpy())  # PyTorch

    # Filtrar solo las emociones que nos interesan
    if label not in emotions_map:
        continue

    save_path = os.path.join(base_dir, emotions_map[label])
    counters[label] += 1
    filename = f"{counters[label]}.png"
    save_image(np.array(img_tensor), save_path, filename)

print("¬°Train dataset exportado!")
print("Conteo final por emoci√≥n:", counters)

import os
from pathlib import Path
from PIL import Image
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import random

# Carpeta base del train
base_dir = "/content/emociones_dataset/train"

# Clases
emotions_map = {0:"Enojo", 1:"Asco", 2:"Miedo", 3:"Alegr√≠a", 4:"Tristeza"}
TARGET = 5000  # n√∫mero de im√°genes deseadas por clase

# Configuraci√≥n de data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Funci√≥n para balancear cada clase
def balance_class(emotion_name):
    folder = os.path.join(base_dir, emotion_name)
    images = [f for f in os.listdir(folder) if f.endswith('.png')]
    n_existing = len(images)

    if n_existing >= TARGET:
        print(f"{emotion_name} ya tiene {n_existing} im√°genes, no se necesita aumentar.")
        return

    print(f"Aumentando {emotion_name}: {n_existing} ‚Üí {TARGET} im√°genes")
    images_to_generate = TARGET - n_existing
    idx = 0

    while images_to_generate > 0:
        # Escoger imagen aleatoria
        img_file = random.choice(images)
        img_path = os.path.join(folder, img_file)
        img = Image.open(img_path)
        img_array = np.array(img)
        # A√±adir canal si es escala de grises
        if len(img_array.shape) == 2:
            img_array = np.expand_dims(img_array, axis=-1)
        img_array = np.expand_dims(img_array, axis=0)  # batch de 1

        # Generar imagen aumentada
        aug_iter = datagen.flow(img_array, batch_size=1)
        aug_img = next(aug_iter)[0].astype(np.uint8)
        # Quitar canal si es gris
        if aug_img.shape[-1] == 1:
            aug_img = aug_img.squeeze(-1)
        # Guardar
        idx += 1
        new_filename = f"aug_{idx+n_existing}.png"
        Image.fromarray(aug_img).save(os.path.join(folder, new_filename))
        images_to_generate -= 1

# Aplicar balanceo a todas las clases
for label, name in emotions_map.items():
    balance_class(name)

print("‚úÖ Dataset balanceado a 5000 im√°genes por clase")

import os
from pathlib import Path
from PIL import Image
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import random
import shutil

# Carpeta base del train
base_dir = "/content/emociones_dataset/train"

# Clases
emotions_map = {0:"Enojo", 1:"Asco", 2:"Miedo", 3:"Alegr√≠a", 4:"Tristeza"}
TARGET = 5000  # n√∫mero de im√°genes deseadas por clase

# Configuraci√≥n de data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Funci√≥n para balancear cada clase
def balance_class(emotion_name):
    folder = os.path.join(base_dir, emotion_name)
    images = [f for f in os.listdir(folder) if f.endswith('.png')]
    n_existing = len(images)

    if n_existing < TARGET:
        print(f"Aumentando {emotion_name}: {n_existing} ‚Üí {TARGET} im√°genes")
        images_to_generate = TARGET - n_existing
        idx = 0
        while images_to_generate > 0:
            img_file = random.choice(images)
            img_path = os.path.join(folder, img_file)
            img = Image.open(img_path)
            img_array = np.array(img)
            # A√±adir canal si es gris
            if len(img_array.shape) == 2:
                img_array = np.expand_dims(img_array, axis=-1)
            img_array = np.expand_dims(img_array, axis=0)  # batch de 1
            # Generar imagen aumentada
            aug_iter = datagen.flow(img_array, batch_size=1)
            aug_img = next(aug_iter)[0].astype(np.uint8)
            if aug_img.shape[-1] == 1:
                aug_img = aug_img.squeeze(-1)
            # Guardar
            idx += 1
            new_filename = f"aug_{idx+n_existing}.png"
            Image.fromarray(aug_img).save(os.path.join(folder, new_filename))
            images_to_generate -= 1

    elif n_existing > TARGET:
        print(f"Recortando {emotion_name}: {n_existing} ‚Üí {TARGET} im√°genes")
        images_to_remove = n_existing - TARGET
        remove_files = random.sample(images, images_to_remove)
        for f in remove_files:
            os.remove(os.path.join(folder, f))
    else:
        print(f"{emotion_name} ya tiene {TARGET} im√°genes, no se necesita hacer nada.")

# Aplicar balanceo a todas las clases
for label, name in emotions_map.items():
    balance_class(name)

print("‚úÖ Dataset balanceado exactamente a 5000 im√°genes por clase")

import os
from collections import Counter

# Carpeta base
base_dir = "/content/emociones_dataset/train"

# Clases
emotions_map = {0:"Enojo", 1:"Asco", 2:"Miedo", 3:"Alegr√≠a", 4:"Tristeza"}

print("üìä Conteo de im√°genes por emoci√≥n despu√©s del balanceo:")

for label, name in emotions_map.items():
    folder = os.path.join(base_dir, name)
    if os.path.exists(folder):
        n_images = len([f for f in os.listdir(folder) if f.endswith('.png')])
        print(f"{name}: {n_images} im√°genes")
    else:
        print(f"{name}: Carpeta no encontrada")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models

# Carpeta de entrenamiento y validaci√≥n
train_dir = "/content/emociones_dataset/train"
# (opcional) si quieres crear un peque√±o validation split desde train
validation_split = 0.2  # 20% para validaci√≥n

# Data augmentation para entrenamiento
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    validation_split=validation_split  # para separar validaci√≥n
)

# Generador de entrenamiento
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(48, 48),
    color_mode='grayscale',
    batch_size=64,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

# Generador de validaci√≥n
validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(48, 48),
    color_mode='grayscale',
    batch_size=64,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(128, (3,3), activation='relu'),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(5, activation='softmax')  # 5 clases
])

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(
    train_generator,
    epochs=10,
    validation_data=validation_generator,
    callbacks=[early_stop]
)

import matplotlib.pyplot as plt

# Accuracy
plt.plot(history.history['accuracy'], label='Entrenamiento')
plt.plot(history.history['val_accuracy'], label='Validaci√≥n')
plt.title('Precisi√≥n del modelo')
plt.xlabel('√âpoca')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Loss
plt.plot(history.history['loss'], label='Entrenamiento')
plt.plot(history.history['val_loss'], label='Validaci√≥n')
plt.title('P√©rdida del modelo')
plt.xlabel('√âpoca')
plt.ylabel('Loss')
plt.legend()
plt.show()

import os
from pathlib import Path
from PIL import Image
import numpy as np

# Emociones que queremos
emotions_map = {0:"Enojo", 1:"Asco", 2:"Miedo", 3:"Alegr√≠a", 4:"Tristeza"}

# Carpeta base para test
base_dir_test = "/content/emociones_dataset/test"
os.makedirs(base_dir_test, exist_ok=True)

# Crear subcarpetas por emoci√≥n
for name in emotions_map.values():
    Path(os.path.join(base_dir_test, name)).mkdir(parents=True, exist_ok=True)

# Funci√≥n para guardar imagen
def save_image(img_array, path, filename):
    if img_array.max() <= 1:
        img_array = (img_array * 255).astype(np.uint8)
    else:
        img_array = img_array.astype(np.uint8)
    # Escala de grises (48,48,1) ‚Üí (48,48)
    if len(img_array.shape) == 3 and img_array.shape[-1] == 1:
        img_array = img_array.squeeze(-1)
    img = Image.fromarray(img_array)
    img.save(os.path.join(path, filename))

# Contadores para nombrar archivos
counters = {label:0 for label in emotions_map.keys()}

# Recorrer todo el dataset test
for i in range(len(test_ds)):
    img_tensor = test_ds[i]["images"]   # o "image" seg√∫n tu dataset
    label_tensor = test_ds[i]["labels"] # o "label"

    # Convertir a entero
    try:
        label = int(label_tensor.numpy())   # TensorFlow
    except:
        label = int(label_tensor.detach().cpu().numpy())  # PyTorch

    # Filtrar solo las emociones que nos interesan
    if label not in emotions_map:
        continue

    save_path = os.path.join(base_dir_test, emotions_map[label])
    counters[label] += 1
    filename = f"{counters[label]}.png"
    save_image(np.array(img_tensor), save_path, filename)

print("‚úÖ Test dataset exportado con √©xito")
print("Conteo final por emoci√≥n:", counters)

test_dir = "/content/emociones_dataset/test"

test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(48,48),
    color_mode='grayscale',
    batch_size=64,
    class_mode='categorical',
    shuffle=False
)

# Evaluaci√≥n
test_loss, test_acc = model.evaluate(test_generator)
print(f"Test Accuracy: {test_acc:.4f}")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

# Obtener predicciones en el test set
Y_pred = model.predict(test_generator, verbose=1)
y_pred = np.argmax(Y_pred, axis=1)

# Etiquetas verdaderas
y_true = test_generator.classes

# Nombres de clases (tomados del generador)
class_names = list(test_generator.class_indices.keys())

# Matriz de confusi√≥n
cm = confusion_matrix(y_true, y_pred)

# Graficar
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicci√≥n")
plt.ylabel("Etiqueta real")
plt.title("Matriz de Confusi√≥n")
plt.show()

# Reporte detallado (precision, recall, f1 por clase)
print(classification_report(y_true, y_pred, target_names=class_names))