# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fwMkFM0w0Mj-4p-zR7Tuv6u7wcof8UHk
"""

!pip install --upgrade pip
!pip install tensorflow==2.20.0 keras==3.10.0

!pip install gdown

!gdown --id 1avh2UeCvgAn4jbJ7xWrv1urpr8_X91Gu

!unzip datasetjunto.zip -d content/

!mkdir -p /content/train

!mv /content/content/* /content/train

import os
import cv2
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

dir_entrenamiento = "/content/train"
nombres_clases = ['alegria', 'enojo', 'miedo', 'neutral', 'tristeza']
objetivo = 7000

# Data augmentation generator
datagen = ImageDataGenerator(
    rotation_range=15,
    brightness_range=[0.7, 1.3],
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

for clase in nombres_clases:
    path_clase = os.path.join(dir_entrenamiento, clase)
    archivos = [f for f in os.listdir(path_clase) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    total_actual = len(archivos)
    faltantes = objetivo - total_actual
    print(f"{clase}: {total_actual} imágenes, faltan {faltantes} para llegar a {objetivo}")

    i = 0
    while faltantes > 0:
        # Seleccionar aleatoriamente una imagen existente
        archivo = np.random.choice(archivos)
        img_path = os.path.join(path_clase, archivo)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (48, 48))  # Asegurarse que todas tengan el mismo tamaño
        img = img.reshape((1, 48, 48, 1))  # Batch de 1 para datagen

        # Generar imagen aumentada
        for batch in datagen.flow(img, batch_size=1):
            nueva_img = batch[0].reshape(48, 48)
            # Guardar la nueva imagen
            nuevo_nombre = f"{os.path.splitext(archivo)[0]}_aug_{i}.png"
            cv2.imwrite(os.path.join(path_clase, nuevo_nombre), nueva_img)
            i += 1
            faltantes -= 1
            if faltantes <= 0:
                break

for clase in nombres_clases:
    print(clase, len(os.listdir(os.path.join(dir_entrenamiento, clase))))

import os
from collections import Counter

dir_entrenamiento = "/content/train"
nombres_clases = ['alegria', 'enojo', 'miedo', 'neutral', 'tristeza']

conteo = {}
for clase in nombres_clases:
    path_clase = os.path.join(dir_entrenamiento, clase)
    archivos = [f for f in os.listdir(path_clase) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    conteo[clase] = len(archivos)

print("=== Número de imágenes por clase ===")
for clase, cantidad in conteo.items():
    print(f"{clase}: {cantidad}")

# === Importar librerías ===
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Activation, RandomFlip, RandomRotation, RandomZoom
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard
import datetime, os
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# === Parámetros ===
ancho_imagen = 48
alto_imagen = 48
tamanio_lote = 32
nombres_clases = ['alegria', 'enojo', 'miedo', 'neutral', 'tristeza']
num_clases = len(nombres_clases)
epocas = 250
seed = 123

# === Rutas dataset ===
dir_entrenamiento = "/content/train"

# === Cargar dataset con valid_split ===
entrenamiento = tf.keras.utils.image_dataset_from_directory(
    dir_entrenamiento,
    labels="inferred",
    label_mode="categorical",
    image_size=(alto_imagen, ancho_imagen),
    batch_size=tamanio_lote,
    color_mode="grayscale",
    shuffle=True,
    validation_split=0.05,
    subset="training",
    seed=seed
)

validacion = tf.keras.utils.image_dataset_from_directory(
    dir_entrenamiento,
    labels="inferred",
    label_mode="categorical",
    image_size=(alto_imagen, ancho_imagen),
    batch_size=tamanio_lote,
    color_mode="grayscale",
    shuffle=True,
    validation_split=0.05,
    subset="validation",
    seed=seed
)

# === Normalización 0-1 ===
normalizar = lambda x, y: (tf.cast(x, tf.float32)/255.0, y)
entrenamiento = entrenamiento.map(normalizar)
validacion = validacion.map(normalizar)

# === Data Augmentation ===
data_augmentation = Sequential([
    RandomFlip("horizontal"),
    RandomRotation(0.1),
    RandomZoom(0.1)
])

# === Modelo CNN Optimizado ===
modelo = Sequential([
    # Aumentación de datos
    data_augmentation,

    # Bloque 1
    Conv2D(32, (3,3), padding='same', input_shape=(alto_imagen, ancho_imagen,1)),
    BatchNormalization(),
    Activation('relu'),
    MaxPool2D((2,2)),
    Dropout(0.2),

    # Bloque 2
    Conv2D(64, (3,3), padding='same'),
    BatchNormalization(),
    Activation('relu'),
    MaxPool2D((2,2)),
    Dropout(0.2),

    # Bloque 3
    Conv2D(128, (3,3), padding='same'),
    BatchNormalization(),
    Activation('relu'),
    MaxPool2D((2,2)),
    Dropout(0.3),

    # Clasificación
    Flatten(),
    Dense(128),
    BatchNormalization(),
    Activation('relu'),
    Dropout(0.3),

    Dense(num_clases, activation='softmax')
])

# === Compilación ===
modelo.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# === Callbacks ===
early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)
log_dir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = TensorBoard(log_dir=log_dir)

# === Entrenamiento ===
historial = modelo.fit(
    entrenamiento,
    validation_data=validacion,
    epochs=epocas,
    callbacks=[early_stop, reduce_lr, tensorboard_callback]
)

# === Guardar modelo ===
modelo.save("modelo_emociones_v7.keras")

# === Evaluación final ===
y_true = []
y_pred = []

for images, labels in validacion:
    preds = modelo.predict(images)
    y_true.extend(np.argmax(labels.numpy(), axis=1))
    y_pred.extend(np.argmax(preds, axis=1))

print("=== Reporte de clasificación ===")
print(classification_report(y_true, y_pred, target_names=nombres_clases))

# === Confusion Matrix ===
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,6))
plt.imshow(cm, cmap='Blues')
plt.title("Matriz de Confusión")
plt.xticks(ticks=np.arange(num_clases), labels=nombres_clases, rotation=45)
plt.yticks(ticks=np.arange(num_clases), labels=nombres_clases)
plt.colorbar()
plt.show()

# ======== GRÁFICA DE ACCURACY ========
plt.figure(figsize=(8,5))
plt.plot(historial.history['accuracy'], label='Entrenamiento')
plt.plot(historial.history['val_accuracy'], label='Validación')
plt.title('Accuracy - Entrenamiento vs Validación')
plt.xlabel('Épocas')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# ======== GRÁFICA DE LOSS ========
plt.figure(figsize=(8,5))
plt.plot(historial.history['loss'], label='Entrenamiento')
plt.plot(historial.history['val_loss'], label='Validación')
plt.title('Pérdida (Loss) - Entrenamiento vs Validación')
plt.xlabel('Épocas')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import numpy as np

def plot_confusion_matrix(cm, classes, title, cmap='Blues'):
    plt.figure(figsize=(6,6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    # === Agregar números dentro de cada celda ===
    thresh = cm.max() / 2
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, format(cm[i, j], 'd'),
                     ha="center", va="center",
                     color="white" if cm[i, j] > thresh else "black",
                     fontsize=12)

    plt.ylabel('Etiqueta real')
    plt.xlabel('Predicción')
    plt.tight_layout()
    plt.show()


# ========= MATRIZ DE CONFUSIÓN VALIDACIÓN =========
y_true_val = []
y_pred_val = []

for images, labels in validacion:
    preds = modelo.predict(images)
    y_true_val.extend(np.argmax(labels.numpy(), axis=1))
    y_pred_val.extend(np.argmax(preds, axis=1))

cm_val = confusion_matrix(y_true_val, y_pred_val)

plot_confusion_matrix(cm_val, nombres_clases, "Matriz de Confusión - VALIDACIÓN", cmap='Blues')

print("\n=== Reporte de clasificación (Validación) ===")
print(classification_report(y_true_val, y_pred_val, target_names=nombres_clases))


# ========= MATRIZ DE CONFUSIÓN TRAIN =========
y_true_train = []
y_pred_train = []

for images, labels in entrenamiento:
    preds = modelo.predict(images)
    y_true_train.extend(np.argmax(labels.numpy(), axis=1))
    y_pred_train.extend(np.argmax(preds, axis=1))

cm_train = confusion_matrix(y_true_train, y_pred_train)

plot_confusion_matrix(cm_train, nombres_clases, "Matriz de Confusión - ENTRENAMIENTO", cmap='Greens')

print("\n=== Reporte de clasificación (Entrenamiento) ===")
print(classification_report(y_true_train, y_pred_train, target_names=nombres_clases))